# -*- coding: utf-8 -*-
"""crop recommendation model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/124YS1WLPxSvuWPN0kACSASEsOBd086Vu
"""

import pandas as pd
import numpy as np
import seaborn as sns
import pickle

df=pd.read_csv("Crop_recommendation.csv")
print(df)

import numpy as np
soil_types = ['sandy', 'clay', 'loamy']
np.random.seed(42)

df['soil_type'] = np.random.choice(soil_types, size=len(df))
print(df[['soil_type']].head())

print(df.shape)

print(df.info())

print(df.isnull().sum())

print(df.duplicated().sum())

print(df.describe())

from sklearn.preprocessing import LabelEncoder

# Suppose df is your DataFrame including soil_type column
le_soil = LabelEncoder()
df['soil_type_encoded'] = le_soil.fit_transform(df['soil_type'])

soil_mapping = {'sandy':0, 'clay':1, 'loamy':2}
df['soil_type_encoded'] = df['soil_type'].map(soil_mapping)

X = df.drop(['label','soil_type'], axis=1)  # remove original soil_type categorical column
X['soil_type_encoded'] = df['soil_type_encoded']  # add encoded column

X = df[['N','P','K','temperature','humidity','ph','rainfall','soil_type_encoded']]

print(X.corr())

print(sns.heatmap(X.corr(), annot=True, cbar=True))

print(df.label.value_counts())

print(df['label'].unique().size)

import matplotlib.pyplot as plt
sns.distplot(df['P'])
plt.show()

import matplotlib.pyplot as plt
sns.distplot(df['N'])
plt.show()

print(df.label.unique())

df_dict={
    'rice': 1,
    'maize': 2,
    'jute': 3,
    'cotton': 4,
    'coconut': 5,
    'papaya': 6,
    'orange': 7,
    'apple': 8,
    'muskmelon': 9,
    'watermelon': 10,
    'grapes': 11,
    'mango': 12,
    'banana': 13,
    'pomegranate': 14,
    'lentil': 15,
    'blackgram': 16,
    'mungbean': 17,
    'mothbeans': 18,
    'pigeonpeas': 19,
    'kidneybeans': 20,
    'chickpea': 21,
    'coffee': 22
}

df['label'] = df['label'].map(df_dict)

print(df.head())

print(df.label.unique())

print(df.label.value_counts())

X=df.drop(['label', 'soil_type'], axis = 1)
y=df['label']

print(X.head())

print(y.head())

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)

print(X_train.shape)

from sklearn.preprocessing import MinMaxScaler
mx = MinMaxScaler()
X_train = mx.fit_transform(X_train)
X_test = mx.transform(X_test)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
sc.fit(X_train)
X_train = sc.transform(X_train)
X_test=sc.transform(X_test)

print(X_train)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
sc.fit(X_train)
X_train = sc.transform(X_train)
X_test=sc.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.metrics import accuracy_score

models = {
    'LogisticRegression': LogisticRegression(),
    'GaussianNB':GaussianNB(),
    'SVC':SVC(),
    'KNeighborsClassifier':KNeighborsClassifier(),
    'DecisionTreeClassifier':DecisionTreeClassifier(),
    'ExtraTreeClassifier':ExtraTreeClassifier(),
    'RandomForestClassifier':RandomForestClassifier(),
    'BaggingClassifier':BaggingClassifier(),
    'GradientBoostingClassifier':GradientBoostingClassifier(),
    'AdaBoostClassifier':AdaBoostClassifier()
}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    score = accuracy_score(y_test, y_pred)
    print(f"{name} model with accuracy: {score}")

randclf = RandomForestClassifier()
randclf.fit(X_train, y_train)
y_pred = randclf.predict(X_test)
print(accuracy_score(y_test, y_pred))

print(df.columns)

def recommendation(N,P,K,temperature,humidity,ph,rainfall, soil_type_encoded):
    features = np.array([[N,P,K,temperature,humidity,ph,rainfall, soil_type_encoded]])
    mx_features = mx.transform(features) 
    sc_mx_features = sc.transform(mx_features)
    prediction = randclf.predict(sc_mx_features).reshape(1,-1)
    return prediction[0]

print(df.head())

N=90
P= 42
K= 43
temperature= 20.879744
humidity=82.002744
ph=6.502985
rainfall=202.935536
soil_type_encoded=0 

predict = recommendation(N,P,K,temperature,humidity,ph,rainfall, soil_type_encoded)

print(predict)

pickle.dump(randclf, open('model.pkl', 'wb'))
pickle.dump(mx, open('minmaxscaler.pkl', 'wb'))
pickle.dump(sc, open('standscaler.pkl', 'wb'))
